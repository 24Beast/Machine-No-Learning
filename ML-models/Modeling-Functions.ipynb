{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Neural Network / Multi Layer Perceptron Network\n",
    "\n",
    "\n",
    "# inputs to the construction function:\n",
    "# number of layers(compulsory, including input and output layers, >=2)\n",
    "# number of input variables(compulsory)\n",
    "# number of output variables(compulsory)\n",
    "# type of model: Regression or Classification (Default: Regression)\n",
    "# array of number of nodes in each hidden layer (Default: increases uniformly for half of the layers and then decreases uniformly for the latter half)\n",
    "# activation functions excluding input layer(Default: None for hidden layers and for output layer: Softmax(Classification) or None(Regression))\n",
    "# \n",
    "\n",
    "def createDenseNetwork(numberOfLayers, numberOfInputNodes, numberOfOutputNodes, typeOfModel = \"Regression\", hiddenLayerNodes = None, activationFunctions = None):\n",
    "    \n",
    "    # Writing the starting includes in the model.py file\n",
    "    f = open(\"model.py\",'w')\n",
    "    f.write(\"import tensorflow as tf \\nimport numpy as np \\nfrom tensorflow.keras import Sequential \\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten \\nfrom math import floor, ceil\\n\")    \n",
    "    f.write(\"class modelToBeImported():\\n\\tdef createModel(self):\\n\")\n",
    "    \n",
    "    layersAdded = 0\n",
    "    \n",
    "    # model initialisation\n",
    "    model = Sequential()\n",
    "    f.write(\"\\t\\tself.model = Sequential()\\n\")\n",
    "    \n",
    "    # Handling stupid exceptions\n",
    "    \n",
    "    if activationFunctions == None:\n",
    "        \n",
    "        activationFunctions = [None]*(numberOfLayers-1)\n",
    "    \n",
    "    if numberOfLayers<2:\n",
    "        \n",
    "        print(\"Dude seriously??!!!!!! number of layers is less than 2, not possible...\")\n",
    "        # throw exception\n",
    "        return model\n",
    "    \n",
    "    elif (int(numberOfInputNodes) != numberOfInputNodes):\n",
    "        \n",
    "        print(\"Bro seriously?! fractional nodes?!\")\n",
    "        # throw exception\n",
    "        return model\n",
    "    \n",
    "    # no hidden layers\n",
    "    \n",
    "    elif numberOfLayers == 2:\n",
    "        \n",
    "        f.write(\"\\t\\tself.\")\n",
    "        model.add(Dense(numberOfOutputNodes, input_shape = (numberOfInputNodes,), activation = activationFunctions[0]))\n",
    "        f.write(\"model.add(Dense({}, input_shape = ({},), activation = {}))\\n\".format(numberOfOutputNodes, numberOfInputNodes, None if (activationFunctions[0] == None) else (\"\\\"{}\\\"\".format(activationFunctions[0]))))\n",
    "        model.summary()\n",
    "        layersAdded += 1\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        numberOfHiddenLayers = numberOfLayers - 2\n",
    "        \n",
    "        if hiddenLayerNodes == None:\n",
    "            # If the number of nodes in each layer are not specified\n",
    "            \n",
    "            threshold = 512\n",
    "            \n",
    "            # Input layer\n",
    "            f.write(\"\\t\\tself.\")\n",
    "            model.add(Dense(min(numberOfInputNodes*2,threshold), input_shape = (numberOfInputNodes,), activation = activationFunctions[layersAdded]))\n",
    "            f.write(\"model.add(Dense({}, input_shape = ({},), activation = {}))\\n\".format(min(numberOfInputNodes*2,threshold),numberOfInputNodes,None if (activationFunctions[layersAdded] == None) else (\"\\\"{}\\\"\".format(activationFunctions[layersAdded]))))\n",
    "            \n",
    "            layersAdded += 1\n",
    "            \n",
    "            # print(\"numberOfHiddenLayers: \\t\",ceil(numberOfHiddenLayers))\n",
    "            # print(\"Ceil value: \\t\",ceil(numberOfHiddenLayers/2))\n",
    "            \n",
    "            # Increasing the number of nodes for first half of the network\n",
    "            \n",
    "            for layer in range(1,ceil(numberOfHiddenLayers/2)):\n",
    "                nodeCount = min(numberOfInputNodes*(2**(layer+1)),threshold)\n",
    "                f.write(\"\\t\\tself.\")\n",
    "                model.add(Dense(nodeCount, activation = activationFunctions[layersAdded]))\n",
    "                f.write(\"model.add(Dense({}, activation = {}))\\n\".format(nodeCount,None if (activationFunctions[layersAdded] == None) else (\"\\\"{}\\\"\".format(activationFunctions[layersAdded]))))\n",
    "                layersAdded += 1\n",
    "                print(nodeCount)\n",
    "                \n",
    "            # Decreasing the number of nodes for the second half of the network\n",
    "            \n",
    "            for layer in range(ceil(numberOfHiddenLayers/2),numberOfHiddenLayers):\n",
    "                nodeCount = int(nodeCount/2)\n",
    "                nodeCount = max(nodeCount,numberOfOutputNodes)\n",
    "                f.write(\"\\t\\tself.\")\n",
    "                model.add(Dense(nodeCount, activation = activationFunctions[layersAdded]))\n",
    "                f.write(\"model.add(Dense({}, activation = {}))\\n\".format(nodeCount,None if (activationFunctions[layersAdded] == None) else (\"\\\"{}\\\"\".format(activationFunctions[layersAdded]))))\n",
    "                layersAdded += 1\n",
    "        \n",
    "        else:\n",
    "            # Number of nodes is specified as a list of integers\n",
    "            \n",
    "            # input layer \n",
    "            f.write(\"\\t\\tself.\")\n",
    "            model.add(Dense(hiddenLayerNodes[0], input_shape = (numberOfInputNodes,), activation = activationFunctions[layersAdded]))\n",
    "            f.write(\"model.add(Dense({}, input_shape = ({},), activation = {}))\\n\".format(hiddenLayerNodes[0], numberOfInputNodes, None if (activationFunctions[layersAdded] == None) else (\"\\\"{}\\\"\".format(activationFunctions[layersAdded]))))\n",
    "            layersAdded += 1\n",
    "            \n",
    "            # Hidden layers\n",
    "            for hiddenLayer in range(1,len(hiddenLayerNodes)):\n",
    "                f.write(\"\\t\\tself.\")\n",
    "                model.add(Dense(hiddenLayerNodes[hiddenLayer], activation = activationFunctions[layersAdded]))\n",
    "                f.write(\"model.add(Dense({}, activation = {}))\\n\".format(hiddenLayerNodes[hiddenLayer], None if (activationFunctions[layersAdded] == None) else (\"\\\"{}\\\"\".format(activationFunctions[layersAdded]))))\n",
    "                layersAdded += 1\n",
    "                \n",
    "        # Last Layer: regression or classification\n",
    "        \n",
    "        if typeOfModel == \"Regression\":\n",
    "            \n",
    "            f.write(\"\\t\\tself.\")\n",
    "            model.add(Dense(numberOfOutputNodes, activation = activationFunctions[layersAdded]))\n",
    "            f.write(\"model.add(Dense({}, activation = {}))\\n\".format(numberOfOutputNodes,activationFunctions[layersAdded]))\n",
    "        \n",
    "        elif typeOfModel == \"Classification\":\n",
    "            \n",
    "            f.write(\"\\t\\tself.\")\n",
    "            model.add(Dense(numberOfOutputNodes, activation = \"softmax\" if (activationFunctions[layersAdded] == None) else activationFunctions[layersAdded]))\n",
    "            f.write(\"model.add(Dense({}, activation = {}))\\n\".format(numberOfOutputNodes, \"\\\"softmax\\\"\" if (activationFunctions[layersAdded] == None) else (\"\\\"{}\\\"\".format(activationFunctions[layersAdded]))))\n",
    "\n",
    "        model.summary()\n",
    "        f.close()\n",
    "        \n",
    "        return model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trialModel = createDenseNetwork(2,5,1)\n",
    "trialModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numberOfHiddenLayers: \t 5\n",
      "Ceil value: \t 3\n",
      "20\n",
      "40\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trialModel2 = createDenseNetwork(7,5,1, typeOfModel = \"Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numberOfHiddenLayers: \t 8\n",
      "Ceil value: \t 4\n",
      "20\n",
      "40\n",
      "80\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 80)                3280      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 8,731\n",
      "Trainable params: 8,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trialModel2 = createDenseNetwork(10, 5, 1, typeOfModel=\"Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Pro Coder Debugging\n",
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard 2D-CNN network\n",
    "\n",
    "# structure: upscaling CNN layers followed by flatten layer, followed by downscaling dense layers\n",
    "# \n",
    "# inputs to the construction function:\n",
    "# number of convlayers(compulsory) these do not include the input layer i.e. can be >=1\n",
    "# number of denselayers(compulsory) these do not include the output layer i.e. can be >=1\n",
    "# input_shape((height, width, channels),compulsory)\n",
    "# number of output categories(compulsory)\n",
    "# type of model: Regression or Classification (Default: Classification)\n",
    "# array of number of filters in each conv layer (Default: doubles the number of filters in each conv layer)\n",
    "# array of kernel sizes (Default: 3x3)\n",
    "# array of strides (Default: 1x1)\n",
    "# padding (Default: Valid (i.e. No padding))\n",
    "# \n",
    "# \n",
    "# activation functions(Default: None for hidden layers and for output layer: Softmax(Classification) or None(Regression))\n",
    "# \n",
    "# \n",
    "\n",
    "def create2DCNNNetwork(numOfConvLayers, numOfDenseLayers, inputShape, numOfOutCats, typeOfModel = \"Classification\", numOfFilters = None, kernelSizes = None, strides = None, padding = \"valid\", activationFunctions = None):\n",
    "    \n",
    "    # Writing starting includes in the model.py file\n",
    "    \n",
    "    f = open(\"model.py\",'w')\n",
    "    f.write(\"import tensorflow as tf \\nimport numpy as np \\nfrom tensorflow.keras import Sequential \\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten \\nfrom math import floor, ceil\\n\")    \n",
    "    f.write(\"class modelToBeImported():\\n\\tdef createModel(self):\\n\")\n",
    "    \n",
    "    # Initialising model\n",
    "    model = Sequential()\n",
    "    f.write(\"\\t\\tself.model = Sequential()\\n\")\n",
    "    \n",
    "    # Initialising the number of filters, kernel size, stride, activation function per conv layer list in case it is set to None\n",
    "    \n",
    "    if numOfFilters == None:\n",
    "        fs = inputShape[-1]\n",
    "        numOfFilters = []\n",
    "        \n",
    "        for i in range(numOfConvLayers):\n",
    "            numOfFilters.append(2*fs)\n",
    "            fs = 2*fs\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if len(numOfFilters != numOfConvLayers):\n",
    "            # throw error\n",
    "            return\n",
    "        \n",
    "    if kernelSizes == None:\n",
    "        \n",
    "        kernelSizes = [3]*numOfConvLayers\n",
    "    \n",
    "    if strides == None:\n",
    "        \n",
    "        strides = [(1,1)]*numOfConvLayers\n",
    "    \n",
    "    if activationFunctions == None:\n",
    "        \n",
    "        activationFunctions = [None]*(numOfConvLayers+numOfDenseLayers)\n",
    "        \n",
    "        if typeOfModel == \"Classification\":\n",
    "            activationFunctions.append(\"softmax\")\n",
    "    \n",
    "    # Adding Convolution Layers: default pattern follows doubling number of filters\n",
    "    f.write(\"\\t\\tself.\")\n",
    "    model.add(Conv2D(numOfFilters[0], kernelSizes[0], strides[0], padding, input_shape = (inputShape[-3],inputShape[-2], inputShape[-1]), activation = activationFunctions[0]))\n",
    "    f.write(\"model.add(Conv2D({}, {}, {}, \\\"{}\\\", input_shape = ({},{}, {}), activation = {}))\\n\".format(numOfFilters[0], kernelSizes[0], strides[0], padding, inputShape[-3],inputShape[-2], inputShape[-1], None if (activationFunctions[0] == None) else (\"\\\"{}\\\"\".format(activationFunctions[0]))))\n",
    "    \n",
    "    for i in range(1,numOfConvLayers):\n",
    "        f.write(\"\\t\\tself.\")\n",
    "        model.add(Conv2D(numOfFilters[i], kernelSizes[i], strides[i], padding, activation = activationFunctions[i]))\n",
    "        f.write(\"model.add(Conv2D({}, {}, {}, \\\"{}\\\", activation = {}))\\n\".format(numOfFilters[i], kernelSizes[i], strides[i], padding, None if (activationFunctions[i] == None) else (\"\\\"{}\\\"\".format(activationFunctions[i]))))\n",
    "    \n",
    "    # Adding flattening later to change [height, width, filters] to [height x width x filters]\n",
    "    model.add(Flatten())\n",
    "    f.write(\"\\t\\tself.model.add(Flatten())\\n\")\n",
    "    \n",
    "    # Adding Dense Layers: default pattern follows number of nodes = max(outCategories, previousLayerNodes/2)\n",
    "    nodeCount = model.output.shape[-1]\n",
    "    nodeCountArray = []\n",
    "    nodeCount = max(int(nodeCount/2),numOfOutCats)\n",
    "    nodeCountArray.append(nodeCount)\n",
    "    \n",
    "    for i in range(numOfDenseLayers):\n",
    "        nodeCount = max(int(nodeCount/2),numOfOutCats)\n",
    "        nodeCountArray.append(nodeCount)\n",
    "    # print(activationFunctions)\n",
    "    \n",
    "    for i in range(numOfDenseLayers):\n",
    "        f.write(\"\\t\\tself.\")\n",
    "        model.add(Dense(nodeCountArray[i], activation = activationFunctions[i+numOfConvLayers]))\n",
    "        f.write(\"model.add(Dense({}, activation = {}))\\n\".format(nodeCountArray[i], None if (activationFunctions[i+numOfConvLayers] == None) else (\"\\\"{}\\\"\".format(activationFunctions[i+numOfConvLayers]))))\n",
    "    \n",
    "    f.write(\"\\t\\tself.\")\n",
    "    model.add(Dense(numOfOutCats, activation = activationFunctions[-1]))\n",
    "    f.write(\"model.add(Dense({}, activation = {}))\\n\".format(numOfOutCats, None if (activationFunctions[-1] == None) else (\"\\\"{}\\\"\".format(activationFunctions[-1]))))\n",
    "    \n",
    "    model.summary()\n",
    "    f.close()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, 'softmax']\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 6)         168       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 12)          660       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 6, 6, 24)          2616      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 432)               373680    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 216)               93528     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 108)               23436     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 54)                5886      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 165       \n",
      "=================================================================\n",
      "Total params: 500,139\n",
      "Trainable params: 500,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 6)         168       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 12)          660       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 6, 6, 24)          2616      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 432)               373680    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 216)               93528     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 108)               23436     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 54)                5886      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 165       \n",
      "=================================================================\n",
      "Total params: 500,139\n",
      "Trainable params: 500,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cMod = create2DCNNNetwork(3, 4, (12,12,3), 3)\n",
    "cMod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 6)         168       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 12)        660       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6912)              0         \n",
      "=================================================================\n",
      "Total params: 828\n",
      "Trainable params: 828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6912\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(6, 3, input_shape = (28,28,3)))\n",
    "model.add(Conv2D(12, 3))\n",
    "model.add(Flatten())\n",
    "model.summary()\n",
    "print(model.output.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Models: traditional ML\n",
    "\n",
    "class Model_Creator():\n",
    "    \n",
    "    def __init__(self,opt):\n",
    "        self.model_type = opt[\"model_type\"]\n",
    "        self.model_args = opt[\"model_args\"]\n",
    "        self.model = None\n",
    "        \n",
    "    def get_new_model(self):\n",
    "        if(self.model_type.split(\"_\")[-1]==\"Regressor\"):\n",
    "            if(self.model_type == \"Linear-Regressor\"):\n",
    "                from sklearn.linear_model import LinearRegression\n",
    "                self.model = LinearRegression(**self.model_args)\n",
    "            elif(self.model_type == \"Support-Vector-Regressor\"):\n",
    "                import sklearn.svm as SVR\n",
    "                self.model = SVR(**self.model_args)\n",
    "            elif(self.model_type == \"Decision-Tree-Regressor\"):\n",
    "                from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "                self.model = DTR(**self.model_args)\n",
    "            elif(self.model_type == \"Random-Forest-Regressor\"):\n",
    "                from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "                self.model = RFR(**self.model_args)\n",
    "        else:\n",
    "            if(self.model_type == \"Logistic-Regression-Classifier\"):\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                self.model = LogisticRegression(**self.model_args)\n",
    "            elif(self.model_type == \"KNN-Classifier\"):\n",
    "                from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "                self.model = KNN(**self.model_args)\n",
    "            elif(self.model_type == \"Support-Vector-Classifier\"):\n",
    "                import sklearn.svm as SVC\n",
    "                self.model = SVC(**self.model_args)\n",
    "            elif(self.model_type == \"Naive-Bayes-Classifier\"):\n",
    "                from sklearn.naive_bayes import GNB\n",
    "                self.model = GNB(**self.model_args)\n",
    "            elif(self.model_type == \"Decision-Tree-Classifier\"):\n",
    "                from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "                self.model = DTC(**self.model_args)\n",
    "            elif(self.model_type == \"Random-Forest-Classifier\"):\n",
    "                from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "                self.model = RFC(**self.model_args)\n",
    "    \n",
    "    # Include train in the main.py file (written in continuation to the dataloading file)\n",
    "    def train(self,X,y,val_size=0.2):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train,X_val,y_train,y_val = train_test_split(X,y, test_size=val_size)\n",
    "        self.model.fit(X_train,y_train)\n",
    "        if(self.model_type.split(\"_\")[-1]==\"Regressor\"):\n",
    "            from sklearn.metrics import mean_squared_error as mse\n",
    "            from sklearn.metrics import r2_score as r2\n",
    "            y_pred_train = self.model.predict(X_train)\n",
    "            print(\"Training Scores:\")\n",
    "            print(\"MSE : \"+str(mse(y_train,y_pred_train)))\n",
    "            print(\"R-Squared-Score : \"+str(r2(y_train,y_pred_train)))\n",
    "            if(val_size!=0):\n",
    "                y_pred_val = self.model.predict(X_val)\n",
    "                print(\"Validation Scores:\")\n",
    "                print(\"MSE : \"+str(mse(y_val,y_pred_val)))\n",
    "                print(\"R-Squared-Score : \"+str(r2(y_val,y_pred_val)))\n",
    "        else:\n",
    "            from sklearn.metrics import classification_report as cr\n",
    "            y_pred_train = self.model.predict(X_train)\n",
    "            print(\"Training Scores:\")\n",
    "            print(\"MSE : \"+str(cr(y_train,y_pred_train)))\n",
    "            if(val_size!=0):\n",
    "                y_pred_val = self.model.predict(X_val)\n",
    "                print(\"Validation Scores:\")\n",
    "                print(\"MSE : \"+str(cr(y_val,y_pred_val)))\n",
    "    \n",
    "    # No need for the below functions in the model function creation file, include them in the main.py file\n",
    "    def predict(self,X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def save_model(self,save_dir=\"\",model_name=\"Sample_Model\"):\n",
    "        import pickle\n",
    "        fname = save_dir+\"/\"+model_name+\".sav\"\n",
    "        with open(fname,\"wb\") as f:\n",
    "            pickle.dump(self.model,f)\n",
    "    \n",
    "    def load_model(self,model_loc):\n",
    "        if(model_loc==None):\n",
    "            print(\"Model Not Found.\")\n",
    "        else:\n",
    "            import pickle\n",
    "            with open(model_loc,\"rb\") as f:\n",
    "                self.model = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample definitions\n",
    "\n",
    "# Imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Common args:\n",
    "model_type = opt[\"model_type\"]\n",
    "model_args = opt[\"model_args\"]\n",
    "\n",
    "\n",
    "\n",
    "def linearRegressionConstructor(includeIntercept = True, normalizeData = False, copyX = True):\n",
    "    # includeIntercepts: if the data is centered around 0, we don't need this, basically handles bias\n",
    "    # normalizeData: normalisation involves subtracting mean and dividing by l2-norm\n",
    "    # copyX: in case of normalising the data, the original may or may not be overwritten, this creates a copy of the data\n",
    "    includeIntercept = model_args[0]\n",
    "    normalizeData = model_args[1]\n",
    "    copyX = model_args[2]\n",
    "    model = LinearRegression(includeIntercept, normalizeData, copyX)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
